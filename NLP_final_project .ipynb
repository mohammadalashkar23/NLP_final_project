{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ML with TF-IDF (movie rating)\n",
    "- read and prepare training data (read positive and negative data)\n",
    "- split training data into train and test\n",
    "- run different classifier\n",
    "    - naive Bayes\n",
    "    - random forests\n",
    "    - support vector machine\n",
    "    - multi- layer perceptron (MLP)\n",
    "- evaluate / compare\n",
    "\n",
    "### Tasks:\n",
    "- pre-process features in different ways, as in the previous task:  \n",
    "    - lower case, stemmer (porter, ours)\n",
    "    - replace (NER)\n",
    "    - compute TF-IDF / w2v (1, 2, .. n-grams)\n",
    "    - filter most important terms/reduce vector size\n",
    "- compare precision, recall accuracy of classifiers for vector sizes\n",
    "- modify parameters of classifiers\n",
    "- fold cross validation (using different training/testing) sets\n",
    "- document and report in a markup cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "- documents collection $D: \\{d_1 ... d_n\\}$\n",
    "- terms $t_i$\n",
    "\n",
    "-----\n",
    "Term Frequency (TF):\n",
    "- TF($t,d$) = $\\frac{\\mbox{Number of times term $t$ appears in document $d$}} {\\mbox{Total number of terms in the document $d$}}$\n",
    "\n",
    "Inverse Document Frequncy (IDF):\n",
    "\n",
    "- IDF($t,D$) = $log(\\frac{\\mbox{Number of documents $d$ in the corpus ($|d \\in D|$)}} {\\mbox{number of documents $d \\in D$ where the term $t$ appears}})$\n",
    "\n",
    "TF-IDF:\n",
    "- TF-IDF($t, d, D$) = TF($t, d$) * IDF($t,D$)\n",
    "\n",
    "-----\n",
    "Functions:\n",
    "- T = TF_IDF(D): Train TF_IDF structure for document collection D  \n",
    "- W = TF_IDFvector(D, T): Return vector of tf-idf values\n",
    "- L = labelVector(W, T, m=1): Return vector of labels, (m highest terms per document)\n",
    "- B = bestTFIDF(D, n=10): Return union of n highest-ranked terms per document in collection\n",
    "- nBestIndex(T, nBest): re-assign TF_IDF structure for nBest terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This projects has markdown cells to document what is happinging in each cell in addition to some comments in the code\n",
    "## NOTE: Both of us will submit the python script but they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# Mohammad\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read n files from directory and preprocess\n",
    "\n",
    "This code snippet defines a function `ReadSourceTok` and a helper function `preprocessSent`.\n",
    "\n",
    "## Function: `ReadSourceTok(dic, n=100, tag=False, verbose=0)`\n",
    "- **Purpose**: Reads and preprocesses documents from a specified directory.\n",
    "- **Returns**: A dictionary `D` where each document `doc` is represented as a list of preprocessed sentences `sent`, which in turn is represented as a list of preprocessed words `word`.\n",
    "\n",
    "## `preprocessSent(sent)`\n",
    "- **Purpose**: Preprocesses a single sentence.\n",
    "- **Parameters**:\n",
    "  - `sent`: Input sentence to be preprocessed.\n",
    "- **Returns**: The preprocessed sentence.\n",
    "\n",
    "## Preprocessing Steps:\n",
    "1. Remove HTML tags using BeautifulSoup.\n",
    "2. Remove punctuation and numbers using regular expressions.\n",
    "3. Tokenize the sentence and perform part-of-speech tagging.\n",
    "4. Handle contractions like \"n't\" and combine them with the following word.\n",
    "5. Remove named entities recognized by NLTK's named entity recognition.\n",
    "6. Remove stopwords and stem the remaining words using the Porter Stemmer algorithm.\n",
    "\n",
    "### Why Did We Choose These Steps?\n",
    "\n",
    "1. **Removing HTML Tags, Numbers, and Punctuation**:\n",
    "   - **Purpose**: HTML tags, numbers, and punctuation do not contribute to the semantic meaning of the text and only add noise to the data. Removing them helps reduce the dimensionality of vector.\n",
    "\n",
    "2. **Removing Stopwords**:\n",
    "   - **Purpose**: Stopwords are common words (e.g., \"the\", \"is\", \"and\") that occur frequently in the text but often do not carry significant meaning. Removing stopwords also reduces the size of the vector.\n",
    "\n",
    "3. **Handling Contractions (e.g., \"n't\")**:\n",
    "   - **Purpose**: Contractions like \"n't\" (e.g., \"not\") can significantly change the meaning of words (e.g., \"happy\" vs. \"not happy\"). Concatenating \"not\" with the following word (e.g., \"not_happy\") preserves the negation context, ensuring that the sentiment conveyed by the word is correctly captured during subsequent analysis.\n",
    "\n",
    "4. **Stemming**:\n",
    "   - **Purpose**: Stemming reduces words to their root or base form, which helps in capturing the core meaning of words and reduces the size of the vector (e.g using and use will be the same ).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read n files from directory and preprocess\n",
    "# return: D[doc][sent][word]\n",
    "\n",
    "def ReadSourceTok(dic, n=100,  tag = False, verbose = 0) :\n",
    "    D = {}\n",
    "    i = 0\n",
    "\n",
    "    # Read sorted file names\n",
    "    for f in sorted(Path(dic).iterdir()):\n",
    "        if(verbose == 1): print(f.resolve())\n",
    "        if (i == n): break\n",
    "        i += 1\n",
    "        \n",
    "        with f.open('r', encoding='utf-8') as fhin: data = fhin.read()\n",
    "            \n",
    "        # get the file basename as index for document\n",
    "        b = os.path.basename(f).split(\".\")[0]\n",
    "        \n",
    "        # document is a string of tokens\n",
    "        D[b] = preprocessSent(data)\n",
    "    return D\n",
    "\n",
    "   \n",
    "def preprocessSent(sent):\n",
    "    soup = BeautifulSoup(sent, \"html.parser\")\n",
    "    sent = soup.get_text()\n",
    "    words = sent.split(' ')\n",
    "    for i, word in enumerate(words):\n",
    "        if \"'t\" in word:\n",
    "            words[i] = word.replace(\"'t\", \" not\")\n",
    "    sent = \" \".join(words)\n",
    "    sent = sent.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove numbers\n",
    "    sent = re.sub(r'\\d+', '', sent)\n",
    "    tagged_words = pos_tag(words)\n",
    "    processed_words = []\n",
    "    i = 0\n",
    "    while i < len(tagged_words):\n",
    "        word, tag = tagged_words[i]\n",
    "        if word == \"not\" and i < len(tagged_words) - 1:\n",
    "            processed_words.append(word + \"_\" + tagged_words[i+1][0])\n",
    "            i += 2\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "            i += 1\n",
    "    tagged_words = pos_tag(processed_words)\n",
    "    named_entities = nltk.ne_chunk(tagged_words)\n",
    "    processed_words2 = []\n",
    "    for word in named_entities:\n",
    "        if not isinstance(word, nltk.tree.Tree):\n",
    "            # If it's a named entity, replace it with 'NER'\n",
    "            processed_words2.append(word[0].lower())\n",
    "    # add here additional preprocessing steps\n",
    "    # Remove stopwords\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_words2 = [word for word in processed_words2 if word not in stop_words]\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stemmed_words = [porter_stemmer.stem(word) for word in processed_words2]\n",
    "    \n",
    "    sent = \" \".join(stemmed_words)        \n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "It is just a small exaple to see how the preprocessSent() function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'process text custom stem algorithm'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"Processing text with Porter Stemmer and custom stemming algorithm\"\n",
    "result= preprocessSent(example_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Label Sparse Vectors Based on Top Features\n",
    "The **labelVector** function labels a collection of sparse vectors by identifying the top features from each vector. \n",
    "\n",
    "## Parameters:\n",
    "1. **vectors**: An iterable of sparse vectors.\n",
    "2. **model**: An object that provides the feature names (like a TfidfVectorizer in scikit-learn).\n",
    "3. **m**: The number of top features to extract from each vector (default is 1).\n",
    "\n",
    "## Workflow:\n",
    "1. **Initialization:**\n",
    "    - Create an empty list labels to store the labels for each vector.\n",
    "2. **Processing Each Vector:**\n",
    "    - Loop through each vector in vectors.\n",
    "    - Determine the indices of the top m features with the highest values in the vector. This is done using np.argsort(vector.data)[-m:][::-1].\n",
    "    - Ensure the indices are within bounds by filtering out indices larger than the number of feature names.\n",
    "    - Extract the top terms using these indices: [(feature_names[vector.indices[i]], vector.data[i])]. This list comprehension pairs the feature names with their corresponding values.\n",
    "    - Sort the top terms by their values in descending order using top_terms.sort(key=lambda x: x[1], reverse=True).\n",
    "    - Extract the feature names from the sorted list of top terms to get the top labels.\n",
    "3. **Appending to Labels:**\n",
    "    - Append the list of top labels to the labels list for each vector.\n",
    "4. **Return:**\n",
    "    - The function returns the labels list containing the top labels for each vector.\n",
    "\n",
    "## How did we use this function?\n",
    " We were trying to get the m best words in the positive documents and negative ones (according to their TFIDF scores) and then refeed them to the machine from the beginning to make judgements later based on these words only instead of all the words in the documents. This approach obviously reduced the size of the vector and helped us read more and more files as it solved the space constraint, but we noticed that the accuracy dropped significantly as expected (to 0.4 or less).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelVector(vectors, model, m=1): \n",
    "    labels = []\n",
    "    feature_names = model.get_feature_names()\n",
    "    for vector in vectors:\n",
    "        top_indices = vector.argsort()[-m:][::-1]\n",
    "        top_terms = [(feature_names[i], vector[i]) for i in top_indices]\n",
    "        top_terms.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_labels = [term[0] for term in top_terms]\n",
    "        labels.append(top_labels)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Files\n",
    "\n",
    "We read a total of 1600 documents( 800 positive and 800 negative). Due to resource limitations on this server, we were unable to read more documents. However, by performing data cleaning and removing unnecessary words during the preprocessing step, we were able to increase the number of documents we could process to 1600. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/bs4/__init__.py:439: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Pos:800 #words in Docs:604412\n",
      "#Neg:800 #words in Docs:589626\n",
      "#Sum:1600 #words in Docs:1194038\n"
     ]
    }
   ],
   "source": [
    "# add TF-IDF model for pos and neg documents\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "# number of docs to read\n",
    "nDocs = 800\n",
    "\n",
    "#initialize \n",
    "D1 = N1 = P1 = {}\n",
    "\n",
    "# Read positive documents \n",
    "P1 = ReadSourceTok(\"/data/critt/shared/resources/aclImdb/test/pos/\", n=nDocs, tag=False)\n",
    "\n",
    "# Read negative documents \n",
    "N1 = ReadSourceTok(\"/data/critt/shared/resources/aclImdb/test/neg/\", n=nDocs, tag=False)\n",
    "\n",
    "# join the Pos and the Neg corpus\n",
    "D1 = {**P1,**N1}\n",
    "\n",
    "print(f\"#Pos:{len(P1)} #words in Docs:{len([w for d in P1.keys() for s in P1[d] for w in s])}\")\n",
    "print(f\"#Neg:{len(N1)} #words in Docs:{len([w for d in N1.keys() for s in N1[d] for w in s])}\")\n",
    "print(f\"#Sum:{len(D1)} #words in Docs:{len([w for d in D1.keys() for s in D1[d] for w in s])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "\n",
    "1. **Creation of TF-IDF Vectorizer**:\n",
    "   - A TF-IDF vectorizer (`tfidf`) is created with unigram (1-gram) range. This means that only single words are considered as features for vectorization.\n",
    "   \n",
    "2. **Reasoning for Using Unigram Range**:\n",
    "   - The decision to use a unigram range is based on the preprocessing steps performed earlier. By removing stopwords, many meaningful sequences such as \"very good\" have been broken. Additionally, by concatenating \"not\" with the following word (e.g., \"not_good\"), the two words are treated as one token with the full meaning of a bigram (2-gram), such as \"not good\" = \"bad\".\n",
    "   - Therefore, there is no need to use more than one gram in the TF-IDF vectorization process, as the preprocessing steps have already handled the meaningful combinations of words effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Sum:1600 #words in Docs:1194038\n",
      "Length of Tfidf vectors: 17593\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"#Sum:{len(D1)} #words in Docs:{len([w for d in D1.keys() for s in D1[d] for w in s])}\")\n",
    "# tfidf vector 1  grams\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "# Learn vocabulary and idf from P1 and N1 documents\n",
    "tfidf.fit(D1.values())\n",
    "\n",
    "print(f\"Length of Tfidf vectors: {len(tfidf.get_feature_names())}\")\n",
    " \n",
    "# Transform P1 documents to document-term matrix.\n",
    "Pos1 = tfidf.transform(P1.values())\n",
    "\n",
    "# Transform N1 documents to document-term matrix.\n",
    "Neg1 = tfidf.transform(N1.values())\n",
    "# Transform Pos1 and Neg1 documents to document-term matrix.\n",
    "\n",
    "Ntr1 = Neg1.toarray()  # Convert to dense array before transforming\n",
    "Ptr1 = Pos1.toarray() # Convert to dense array before transforming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Positive labels:[['theater', 'coax'], ['golf', 'open'], ['class', 'golf'], ['fabulous', 'job'], ['prejudic', 'golf'], ['golfer', 'golf'], ['drug', 'himself'], ['cultur', 'aspect'], ['depress', 'movi'], ['identity', 'lennon'], ['drug', 'channel'], ['spoli', 'mesmerizing'], ['foreign', 'loophol'], ['famili', 'hurt'], ['mental', 'health'], ['jia', 'film'], ['hunted', 'night'], ['porn', 'deterior'], ['memori', 'particularli'], ['desolate', 'thril'], ['woman', 'drive'], ['felix', 'cartoon'], ['deeper', 'love'], ['anim', 'silent'], ['shoe', 'boss'], ['chaplin', 'strip'], ['ham', 'cartoon'], ['cartoons', 'old'], ['havilland', 'flynn'], ['custer', 'command'], ['custer', 'militari'], ['dictatori', 'buttler'], ['custer', 'battlefield'], ['spoli', 'mesmerizing'], ['legend', 'custer'], ['custer', 'warner'], ['warner', 'dehavilland'], ['never', 'histor'], ['custer', 'war'], ['flynn', 'butler'], ['anti', 'histor'], ['battl', 'movi'], ['custer', 'indian'], ['custer', 'cav'], ['allow', 'film'], ['flynn', 'play'], ['west', 'carpetbagg'], ['flynn', 'streak'], ['havilland', 'wife'], ['custer', 'havilland'], ['custer', 'libby'], ['not_allow', 'photograph'], ['brilliant', 'favourit'], ['custer', 'gerri'], ['militari', 'war'], ['vera', 'dylan'], ['custer', 'flamboy'], ['custer', 'walsh'], ['custer', 'civil'], ['love', 'crazi'], ['wed', 'bu'], ['rate', 'proudly'], ['ditsi', 'mistaken'], ['alway', 'girl'], ['deep', 'seek'], ['callib', 'evita'], ['jon', 'cat'], ['phat', 'didnt'], ['definit', 'renting'], ['bronxi', 'throwaway'], ['fantastic', 'buster'], ['fumbl', 'puma'], ['aspirations', 'not_ag'], ['flop', 'success'], ['neg', 'humour'], ['madonna', 'loudon'], ['alani', 'rocks'], ['garfield', 'jon'], ['customers', 'alway'], ['madonna', 'play'], ['hit', 'fun'], ['madonna', 'credibl'], ['nyc', 'concert'], ['behold', 'gantry'], ['pirat', 'it'], ['rogu', 'thieves'], ['stand', 'warmest'], ['maximum', 'fuqua'], ['soccer', 'though'], ['adolesc', 'meet'], ['babe', 'bikini'], ['unrat', 'version'], ['element', 'unsettl'], ['girl', 'questions'], ['machinist', 'flute'], ['sisters', 'younger'], ['sister', 'stepmoth'], ['film', 'unlock'], ['su', 'ji'], ['footbal', 'see'], ['house', 'allow'], ['horror', 'movi'], ['forget', 'before'], ['ring', 'consid'], ['soo', 'mi'], ['sad', 'cry'], ['world', 'horror'], ['horror', 'without'], ['horror', 'sisters'], ['10', 'view'], ['hate', 'footbal'], ['short', 'artist'], ['horror', 'pair'], ['sister', 'tale'], ['opiemar', 'hongryeon'], ['eun', 'joo'], ['moth', 'step'], ['su', 'stepmoth'], ['tale', 'object'], ['ghost', 'detail'], ['sisters', 'tale'], ['horror', 'bit'], ['crazi', 'rent'], ['th', 'sisters'], ['copi', 'not_prev'], ['su', 'jeong'], ['radio', 'boy'], ['motiv', 'opinion'], ['nomination', 'cuba'], ['not_overplay', 'review'], ['smiling', 'everyon'], ['radio', 'jones'], ['jr', 'volunt'], ['strang', 'soft'], ['not_judg', 'differences'], ['world', 'we'], ['allow', 'not_depend'], ['gooding', 'poignant'], ['footbal', 'radio'], ['surprising', 'touching'], ['peopl', 'vulnerable'], ['realli', 'wouldn'], ['radio', 'grreat'], ['coach', 'understand'], ['amato', 'film'], ['radio', 'footbal'], ['radio', 'coach'], ['racism', 'warm'], ['nice', 'role'], ['radio', 'town'], ['radio', 'footbal'], ['gooding', 'spectacular'], ['radio', 'helloooooooooo'], ['esbjørn', 'viewer'], ['col', 'trial'], ['gorg', 'emanuelle'], ['affair', 'drama'], ['captain', 'command'], ['loyalti', 'resound'], ['remak', 'coupl'], ['use', 'sera'], ['locat', 'mixed'], ['hitchcock', 'suspens'], ['hitchcock', 'taxidermists'], ['think', 'version'], ['politician', 'score'], ['drag', 'footag'], ['day', 'hitchcock'], ['stewart', 'famou'], ['shall', 'sera'], ['version', '1956'], ['intern', 'remak'], ['hitchcock', 'scari'], ['mckenna', 'dr'], ['mckenna', 'song'], ['son', 'hitchcock'], ['hitchcock', 'mckenna'], ['strang', 'soft'], ['london', 'ambassador'], ['race', 'hitchcock'], ['ben', 'dori'], ['hitchcock', 'que'], ['hitchcock', 'happenings'], ['agent', 'sara'], ['sera', 'cantata'], ['music', 'career'], ['assassin', 'hitchcock'], ['hitchcock', 'wife'], ['video', 'home'], ['dr', 'mckenna'], ['hitchcock', 'drag'], ['song', 'hitchcock'], ['myers', 'aspir'], ['relat', 'funni'], ['alex', 'brian'], ['addit', 'inspir'], ['nev', 'warming'], ['gold', 'train'], ['train', 'thiev'], ['70', 'preachi'], ['train', 'superman'], ['superman', 'fleischer'], ['ship', 'ad'], ['canni', 'astonish'], ['ship', 'period'], ['perfectli', 'exposur'], ['honey', 'eo'], ['deciph', 'cutting'], ['effect', 'friend'], ['show', 'adult'], ['popular', 'chiller'], ['rememb', 'car'], ['velli', 'never'], ['villain', 'hate'], ['fu', 'tan'], ['robot', 'cyborg'], ['vindic', 'bargain'], ['wholesal', 'vindicator'], ['robocop', 'love'], ['lehman', 'fistfight'], ['union', 'immigr'], ['boyfriend', 'person'], ['professor', 'narrat'], ['drama', 'founded'], ['creightons', 'perki'], ['western', 'gem'], ['well', 'before'], ['hire', 'haunt'], ['western', 'best'], ['telegraph', 'jagger'], ['novel', 'led'], ['telegraph', 'westerns'], ['telegraph', 'jagger'], ['beller', 'rape'], ['vanc', 'outlaw'], ['telegraph', 'system'], ['western', 'union'], ['canadians', 'humans'], ['lead', 'perhap'], ['minor', 'fairi'], ['deformed', 'demented'], ['gay', 'fanat'], ['spectacular', 'desserts'], ['sequel', 'rapport'], ['quack', 'flaw'], ['horror', 'film'], ['barker', 'film'], ['mutant', 'shrink'], ['sequel', 'movi'], ['card', 'movi'], ['book', 'movi'], ['monster', 'peopl'], ['monster', 'horror'], ['inform', 'tie'], ['nightbreed', 'monsters'], ['school', '1982'], ['looked', 'monst'], ['good', 'unforgettable'], ['mask', 'scari'], ['mutant', 'midian'], ['nightbreed', 'boone'], ['type', 'mich'], ['monster', 'mayb'], ['drawback', 'references'], ['monster', 'castl'], ['monster', 'horribl'], ['shy', 'felt'], ['though', 'not_entir'], ['movi', 'too'], ['woman', 'long'], ['daili', 'minako'], ['love', '50'], ['nagasaki', 'hilli'], ['milk', 'tanaka'], ['soundtrack', 'american'], ['pick', 'misconceptions'], ['film', 'fine'], ['young', 'vantag'], ['outstand', 'pictur'], ['area', 'north'], ['high', 'day'], ['preach', 'relatable'], ['happening', '1960'], ['certainli', 'pooter'], ['track', 'it'], ['cochise', 'preach'], ['movi', 'favourit'], ['boyz', 'athlet'], ['affect', 'suprised'], ['variou', 'pivotal'], ['goodbye', 'not_pron'], ['psychedel', 'label'], ['sayer', 'maria'], ['may', 'twist'], ['twist', 'psychedelia'], ['exploit', 'pretti'], ['leroy', '1969'], ['sublim', 'experiment'], ['neighbour', 'season'], ['format', 'mini'], ['comedy', 'oneupmanship'], ['summ', 'max'], ['max', 'equilibrium'], ['endeavour', 'featur'], ['appart', 'end'], ['messenger', 'mamouni'], ['not_one', 'ponder'], ['eachoth', 'identities'], ['settl', 'lend'], ['saw', 'film'], ['unjustli', 'snobbish'], ['movi', 'majorli'], ['detailed', 'storie'], ['red', 'roug'], ['roses', 'neatly'], ['perverted', 'think'], ['tête', 'cassell'], ['sadness', 'innat'], ['french', 'littl'], ['phillipp', 'ecoffey'], ['game', 'player'], ['uk', 'schedul'], ['film', 'hitchcock'], ['alice', 'lisa'], ['love', 'lot'], ['max', 'alic'], ['unwinds', 'location'], ['film', 'ladi'], ['stunningli', 'picasso'], ['view', 'three'], ['godaw', 'appartement'], ['confid', 'haine'], ['mini', 'length'], ['short', 'bullet'], ['1982', 'onofrio'], ['coach', 'amaz'], ['championship', 'play'], ['cinema', 'trainspotting'], ['unchart', 'sage'], ['modern', 'euthanasia'], ['sparingly', 'slush'], ['india', 'kapur'], ['caste', 'woman'], ['account', 'devi'], ['seri', 'dvd'], ['focuss', 'marvellous'], ['triumph', 'necessari'], ['churn', 'fought'], ['strong', 'subject'], ['concern', 'depict'], ['short', 'joe'], ['cousin', 'uproari'], ['mcintire', 'highlights'], ['shemp', 'inherit'], ['shemp', 'slapstick'], ['oppenheimer', 'mini'], ['shemp', 'trio'], ['shemp', 'curly'], ['shemp', 'stoog'], ['digger', 'blades'], ['shemp', 'stoog'], ['pooh', 'stoog'], ['watch', 'wallop'], ['boy', 'obsessed'], ['camp', 'show'], ['wazi', 'juic'], ['oppenheimer', 'physicist'], ['summer', 'ha'], ['jewish', 'maid'], ['war', 'other'], ['movi', 'peggi'], ['soldier', 'not_th'], ['jewish', 'portray'], ['befriend', 'girl'], ['appear', 'tv'], ['twisti', 'surprised'], ['remaind', 'its'], ['region', 'seri'], ['leg', 'black'], ['ladd', 'key'], ['rariti', 'immediately'], ['nynke', 'react'], ['mis', '1900'], ['marriag', 'nynk'], ['societi', 'feminism'], ['circumstances', 'drama'], ['brain', 'arachnoid'], ['alan', 'drama'], ['develop', 'backstabbing'], ['dr', 'absolut'], ['howev', 'ago'], ['brain', 'damag'], ['disgust', 'humor'], ['gor', 'lowest'], ['llyod', 'dr'], ['taylor', 'ruler'], ['brain', 'bodi'], ['diner', 'stori'], ['hil', 'sequenc'], ['pppenheimer', 'bills'], ['gangsters', 'anna'], ['gurl', 'moreover'], ['mary', 'raped'], ['over', 'and'], ['campu', 'mary'], ['hastings', 'hast'], ['books', 'poirot'], ['alway', 'togeth'], ['locations', 'success'], ['bit', 'quit'], ['gen', 'bolt'], ['gilchrist', 'genuin'], ['mysteri', 'glee'], ['poirot', 'book'], ['murder', 'discrep'], ['poirot', 'favourit'], ['poirot', 'solicitor'], ['scarecrow', 'fake'], ['movi', 'music'], ['militari', 'armi'], ['unrealistic', 'quit'], ['seri', 'roots'], ['1980i', 'eastalgia'], ['stori', 'fail'], ['visuals', 'childish'], ['sector', 'wender'], ['clouds', 'visual'], ['percept', 'beginn'], ['postur', 'catwalk'], ['joyce', 'allud'], ['5s', 'silicon'], ['short', 'malkovich'], ['bbc', 'earthlink'], ['desir', 'flow'], ['interact', 'cannot'], ['film', 'kurosawa'], ['existenti', 'melodramatic'], ['notte', 'candy'], ['wenders', 'worst'], ['conjur', 'visual'], ['novel', 'critic'], ['antonioni', 'first'], ['beautiful', 'soft'], ['explosions', 'themselves'], ['wolff', 'yorker'], ['ghost', 'horror'], ['dread', 'investig'], ['paranorm', 'film'], ['horror', 'ghost'], ['horror', 'cult'], ['imaginations', 'glitches'], ['kobayashi', 'woman'], ['realli', 'provid'], ['movi', 'far'], ['link', 'film'], ['seri', 'today'], ['19784444', 'branch'], ['alway', 'monsters'], ['series', 'abl'], ['show', 'episod'], ['darkside', 'petit'], ['pioneer', 'frontiersman'], ['complexli', 'whimsey'], ['smorgasboard', 'patho'], ['captur', 'contrastingli'], ['stormar', 'archetyp'], ['product', 'not_avail'], ['somewher', 'perform'], ['lodge', 'stripper'], ['softcor', 'sex'], ['sex', 'sexi'], ['raunch', 'not_shar'], ['territory', 'faceless'], ['rachel', 'ha'], ['tiring', 'bigotry'], ['nativ', 'whitewolf'], ['don', 'not_com'], ['stanwyck', 'morgan'], ['bogosian', 'correctly'], ['bogosian', 'charact'], ['12', 'age'], ['movi', 'sex'], ['teenag', 'friend'], ['amongst', 'guy'], ['ha', 'sad'], ['soundtrack', 'kc'], ['movie', 'buy'], ['virgin', 'school'], ['sakall', 'waiter'], ['can', '80'], ['adult', 'moments'], ['soundtrack', 'pass'], ['guy', 'cring'], ['honest', 'movi'], ['incred', 'teenage'], ['gari', 'karen'], ['end', 'heartbroken'], ['gari', 'but'], ['formula', 'girl'], ['magazin', 'owner'], ['gari', 'film'], ['abort', 'som'], ['halfway', 'fast'], ['gary', 'rick'], ['rent', 'whimper'], ['heart', 'highschool'], ['sex', 'sudden'], ['poetic', 'interpret'], ['solemn', 'characters'], ['viridiana', 'ordet'], ['snow', 'flip'], ['sinc', 'rate'], ['loewenhielm', 'share'], ['th', 'mellow'], ['choic', 'question'], ['food', 'foodculture'], ['babette', 'feast'], ['village', 'depict'], ['god', 'show'], ['babette', 'serv'], ['feast', 'cook'], ['farm', 'greenstreet'], ['fuzz', 'dogma'], ['meal', 'food'], ['babett', 'flock'], ['grace', 'humbl'], ['deliveri', 'wondrous'], ['express', 'profund'], ['feast', 'love'], ['banquet', 'gastronomy'], ['feast', 'candle'], ['art', 'meal'], ['war', 'hero'], ['interpret', 'hear'], ['babett', 'babette'], ['dinesen', 'religi'], ['sister', 'chang'], ['profound', 'life'], ['feast', 'villag'], ['babette', 'true'], ['despit', 'poor'], ['disc', 'film'], ['price', 'prezzo'], ['fish', 'holiday'], ['western', 'spaghetti'], ['wrongli', 'oswald'], ['bacalov', 'killter'], ['scour', 'auction'], ['fists', 'not_diminish'], ['dole', 'roundli'], ['spi', 'vasilikov'], ['core', 'soft'], ['track', 'mistook'], ['softcor', 'chloe'], ['issweet', 'regulars'], ['hopefully', 'fir'], ['sex', 'explicit'], ['bodi', 'chloe'], ['deliv', 'alien'], ['alien', 'jillian'], ['husband', 'predictable'], ['wife', 'impregn'], ['abduct', 'undoubt'], ['alien', 'sex'], ['alien', 'easi'], ['slasher', 'blood'], ['whatwashethinking', 'scintilla'], ['estat', 'over'], ['limitations', 'hard'], ['outstand', 'dolbi'], ['ballerina', 'luck'], ['execut', 'predict'], ['lon', 'webber'], ['sever', 'scrutin'], ['fonda', 'bridget'], ['bochner', 'unmysteri'], ['keach', 'train'], ['lane', 'christma'], ['dion', 'kidder'], ['cojon', 'prefigur'], ['chat', 'spilane'], ['keach', '45'], ['crime', 'film'], ['dudes', 'nominated'], ['starrett', 'terrenc'], ['tuppence', 'earli'], ['christi', 'dealt'], ['book', 'christi'], ['farm', 'perfect'], ['kier', 'gang'], ['distribut', 'nichev'], ['wax', 'tolerance'], ['air', 'rockewel'], ['generations', 'show'], ['cartoon', 'dvd'], ['film', 'fleadh'], ['section', 'today'], ['sweet', 'comment'], ['spoiler', 'shower'], ['dickens', 'equival'], ['doll', 'kid'], ['doll', 'shock'], ['puppet', 'horror'], ['child', 'perhap'], ['saw', 'twice'], ['vacat', 'father'], ['supper', 'line'], ['gr8', 'wen'], ['gorgeou', 'love'], ['baha', 'james'], ['sloane', 'fiancee'], ['original', 'not_remot'], ['upcom', 'puppy'], ['original', 'hire'], ['14', 'borrow'], ['father', 'andre'], ['dreams', 'father'], ['teenag', 'father'], ['wild', 'father'], ['sometim', 'ager'], ['velvet', 'tip'], ['holiday', 'christma'], ['book', 'love'], ['velvet', 'fingersmith'], ['house', 'plan'], ['book', 'kitchen'], ['young', 'maud'], ['book', 'read'], ['mr', 'hate'], ['audienc', 'victrion'], ['stealer', 'opportunist'], ['histor', 'decent'], ['baby', 'farm'], ['ensemble', 'lovingli'], ['evince', 'breathing'], ['book', 'read'], ['fresh', 'victorian'], ['book', 'fingersmith'], ['adaption', 'book'], ['women', 'conflict'], ['maud', 'pearl'], ['lost', 'thoroughly'], ['adapt', 'act'], ['sloan', 'borrow'], ['tip', 'adapt'], ['also', 'charact'], ['humor', 'f0rs4k3n'], ['favorit', 'again'], ['dunn', 'skateboarder'], ['bam', 'surprisingli'], ['bam', 'vallo'], ['asshole', 'dumped'], ['cki', 'humor'], ['wait', 'jtcellphon'], ['famou', 'quaintness'], ['rent', 'definetli'], ['awesome', 'hilarious'], ['genius', 'gered'], ['cky', 'excellence'], ['raab', 'ass'], ['total', 'check'], ['film', 'behind'], ['falcone', 'haggard'], ['jilt', 'cheat'], ['grape', 'not'], ['farm', 'provid'], ['individu', 'cultur'], ['bam', 'like'], ['novak', 'porch'], ['not_suit', 'good'], ['knuckl', 'aaaaagh'], ['hilarious', 'watermelon'], ['bam', 'soundtrack'], ['movi', 'dunn'], ['danc', 'song'], ['larter', 'film'], ['98', 'marigold'], ['christmas', 'liz'], ['prem', 'number'], ['prem', 'danc'], ['bollywood', 'western'], ['coward', 'woolcott'], ['hecht', 'opportunity'], ['publish', 'spoilers'], ['noel', 'cora'], ['teacher', 'character'], ['cannes', 'misstep'], ['french', 'greatest'], ['refus', 'appeal'], ['movie', 'comment'], ['student', 'girl'], ['redefin', 'loath'], ['boris', 'judged'], ['depraved', 'care'], ['erika', 'half'], ['saw', 'scenario'], ['read', 'subtl'], ['piano', 'teacher'], ['cache', 'huppert'], ['connecticut', 'morgan'], ['razor', 'pocket'], ['anti', 'much'], ['book', 'pianiste'], ['erika', 'young'], ['swept', 'teacher'], ['emot', 'society'], ['generation', 'pianiste'], ['thesi', 'tellingly'], ['pianiste', 'jellinek'], ['pronunci', 'jew'], ['us', 'manipul'], ['score', 'work'], ['polit', 'backseat'], ['mislik', 'ussr'], ['shot', 'composed'], ['action', 'step'], ['glass', 'babi'], ['visual', 'gener'], ['sequenc', 'ralli'], ['reiter', 'quantum'], ['eisenstien', 'potempkin'], ['stanwyck', 'season'], ['odessa', 'octob'], ['potempkin', 'film'], ['messag', 'revolt'], ['movi', 'understand'], ['realli', 'film'], ['silent', 'score'], ['bronenoset', 'potyomkin'], ['silent', 'sad'], ['potemkin', 'revolution'], ['frenzi', 'textbook'], ['stanwyck', 'cook'], ['shot', 'eisenstein'], ['rmt', 'limey'], ['potemkin', 'warship'], ['czarist', 'potemkin'], ['potyomkin', 'battleship'], ['shortag', 'footag'], ['medium', 'montag'], ['stairs', 'film'], ['ross', 'sun'], ['ufo', 'chanc'], ['gardiner', 'morgan'], ['reasons', 'era'], ['look', 'models'], ['dopplegang', 'space'], ['aged', 'upn'], ['flight', 'earth'], ['anderson', 'planet'], ['sfx', 'planet'], ['record', 'mic'], ['niggl', 'whenev'], ['sun', 'earth'], ['column', 'stillmeadow'], ['logo', 'productions'], ['thinn', 'sun'], ['earth', 'fx'], ['anderson', 'doppelgänger'], ['interestingli', 'strongest'], ['thinnes', 'doppelganger'], ['space', 'theme'], ['sun', 'side'], ['surprisingli', 'pointed'], ['ninja', 'fight'], ['elizabeth', 'farm'], ['80', 'fun'], ['sho', 'kosugi'], ['ninja', 'ball'], ['ninja', 'ninjas'], ['copi', 'releas'], ['ninja', 'possess'], ['bennett', 'wear'], ['ninja', 'kill'], ['ninja', 'yamada'], ['erot', 'heroin'], ['feel', 'certainli'], ['radha', 'achiev'], ['ninja', 'metion'], ['art', 'firstenberg'], ['scienc', 'ride'], ['footage', 'foreign'], ['poster', 'content'], ['sa', 'favela'], ['neighborhood', 'documentari'], ['unsaf', 'enamor'], ['anderson', 'individu'], ['sá', 'favela'], ['connecticut', 'christma'], ['youth', 'drug'], ['song', 'movi'], ['lovelife', 'laughfest'], ['son', 'hoffman'], ['vs', 'simpl'], ['kramer', 'absolut'], ['ted', 'kramer'], ['billy', 'billi'], ['volatil', 'relationship'], ['kramer', 'ther'], ['dog', 'worker']]\n",
      "#Negative labels:[['costner', 'kutcher'], ['ice', 'heck'], ['homeless', 'nt'], ['nineti', 'ice'], ['pictur', 'qualiti'], ['mortuari', 'mosquito'], ['drink', 'blood'], ['fan', 'cutest'], ['talk', '50'], ['crawford', 'hair'], ['vomit', 'not_mean'], ['thriller', 'suspens'], ['drink', 'shue'], ['erect', 'tout'], ['weren', '80'], ['hero', 'jeep'], ['executioner', 'apocalyps'], ['mang', 'hunters'], ['kher', 'salwar'], ['gaynor', 'niven'], ['stinkaroo', 'insect'], ['killer', 'prey'], ['ask', 'suffici'], ['forest', 'ranger'], ['killer', 'woods'], ['prey', 'pointless'], ['slasher', 'natur'], ['prey', 'slasher'], ['prey', 'the'], ['wildlif', 'forest'], ['butchered', 'forward'], ['slasher', 'prey'], ['bad', 'lep'], ['hit', 'run'], ['prey', 'monster'], ['axe', 'mouth'], ['store', 'sell'], ['pets', 'reimbursed'], ['sicken', 'bathroom'], ['wouldn', 'terribl'], ['possibl', 'herd'], ['fraud', 'grow'], ['bedpan', 'listing'], ['story', 'littl'], ['behav', 'class'], ['filmmak', 'account'], ['movi', 'veng'], ['inconsist', 'til'], ['women', 'comment'], ['minutes', 'comprehension'], ['forewarned', 'tux'], ['breast', 'profound'], ['angst', 'movi'], ['horribl', 'graveyard'], ['think', 'cultists'], ['1986', 'schrecklich'], ['angela', 'teuton'], ['airway', 'plane'], ['author', 'strang'], ['bridg', 'captured'], ['tank', 'rows'], ['skyline', 'smoggi'], ['cowboy', 'shower'], ['sooooo', 'hubby'], ['sutherland', 'man'], ['soundtrack', 'produc'], ['businessmen', 'three'], ['spite', 'manag'], ['christie', 'nile'], ['cristoph', 'inevitably'], ['publicly', 'cliched'], ['bolts', 'fireballs'], ['bad', 'ancient'], ['mediocrity', 'ferrigno'], ['king', 'mino'], ['videogam', 'tier'], ['jp3', 'dinosaur'], ['gang', 'fire'], ['mani', 'jp1'], ['neil', 'dern'], ['graves', 'swiss'], ['dinosaur', 'reli'], ['numb', 'idea'], ['eat', 'dinosaurs'], ['dino', 'standpointeven'], ['jurass', 'dino'], ['island', 'characters'], ['insipid', 'bellybutton'], ['control', 'team'], ['island', 'unthril'], ['thought', 'suspens'], ['previou', 'jp'], ['women', 'white'], ['size', 'sell'], ['model', 'sorri'], ['season', 'tyra'], ['bums', 'temer'], ['plotless', 'goodfellas'], ['melodrama', 'com'], ['law', 'propaganda'], ['rumble', 'street'], ['selv', 'sketchi'], ['wow', 'plan'], ['grader', 'nap'], ['gang', 'leader'], ['dorff', 'gang'], ['imagin', 'cannot'], ['kove', 'corrupt'], ['curves', 'thing'], ['guard', 'wrist'], ['gang', 'outsid'], ['not_expect', 'mean'], ['rodeo', 'bull'], ['psychodrama', 'collaps'], ['good', 'movi'], ['lost', 'bluntly'], ['thouroughli', 'awful'], ['movi', 'look'], ['suppose', 'cack'], ['crappi', 'risky'], ['horror', 'film'], ['terribl', 'll'], ['neighbourhood', 'kill'], ['budget', 'recent'], ['darkhunt', 'auto'], ['terrible', 'film'], ['choo', 'dead'], ['hunter', 'bounti'], ['unclaim', 'soul'], ['dialog', 'time'], ['moggi', 'ponderous'], ['whatev', 'crazi'], ['open', 'bett'], ['provocation', 'gunfire'], ['pretenti', 'fu'], ['bor', 'frenchmen'], ['yes', 'major'], ['walker', 'gardner'], ['song', 'weill'], ['was', 'ngs'], ['risk', 'match'], ['they', 'superpow'], ['vapid', 'narcissist'], ['show', 'blank'], ['referenc', 'dw3'], ['show', 'gomez'], ['sing', 'wood'], ['wagner', 'wood'], ['vampire', 'vampir'], ['coffin', 'vampir'], ['book', 'renauld'], ['show', 'reba'], ['seri', 'ditsi'], ['reba', 'stupid'], ['reba', 'comedi'], ['punk', 'window'], ['suck', 'show'], ['show', 'reba'], ['jean', 'everi'], ['connor', 'roseanne'], ['garbage', 'lower'], ['reba', 'sitcoms'], ['band', 'album'], ['massacre', 'please'], ['crazy', 'clock'], ['movi', 'decid'], ['bronson', 'up'], ['ultra', 'slasher'], ['slumber', 'massacr'], ['charlie', 'made'], ['cours', 'party'], ['woah', 'mean'], ['killer', 'mask'], ['lack', 'expect'], ['slumber', 'movi'], ['wiggly', 'like'], ['cop', 'wholesom'], ['death', 'wish'], ['librari', 'sixti'], ['lethargic', 'duke'], ['sally', 'vile'], ['gang', 'randi'], ['black', 'fraser'], ['owner', 'hidden'], ['disc', 'hotel'], ['thriller', 'mafioso'], ['juror', 'the'], ['asante', 'whalley'], ['sleep', 'lullaby'], ['hell', 'furiou'], ['discuss', 'report'], ['noth', 'mongers'], ['brainwash', 'save'], ['movie', 'masses'], ['religi', 'mostli'], ['pure', 'psycho'], ['christian', 'film'], ['religion', 'believ'], ['atheist', 'explan'], ['quatrilho', 'fishermen'], ['investig', 'subject'], ['felt', 'sublimin'], ['abduct', 'maker'], ['raptur', 'represent'], ['christian', 'believ'], ['christian', 'flicks'], ['fuzzy', 'newbies'], ['holier', 'thou'], ['messag', 'movi'], ['abduct', 'piano'], ['film', 'alpha'], ['church', 'see'], ['scifi', 'user'], ['jc', 'believ'], ['church', 'fine'], ['poorli', 'skeptic'], ['direction', 'bad'], ['quickli', 'fi'], ['sunday', 'church'], ['christian', 'movi'], ['unnecessari', 'please'], ['commentari', 'bad'], ['emili', 'sara'], ['art', 'say'], ['haven', 'strata'], ['hulkster', 'laugh'], ['horribl', 'mcmahon'], ['wrestler', 'severence'], ['wrestl', 'fan'], ['bar', 'gullibl'], ['lol', 'wrestl'], ['atlanta', 'rewrit'], ['bar', 'hold'], ['he', 'performance'], ['hogan', 'promoter'], ['1989', 'standard'], ['wrestl', 'network'], ['wrestl', 'champion'], ['zeus', 'wrestler'], ['stake', 'wrestl'], ['rol', 'character'], ['preview', 'thug'], ['high', 'escap'], ['prominence', 'dispens'], ['concoct', 'random'], ['rehab', 'program'], ['motion', '8mm'], ['suspici', 'ones'], ['green', 'big'], ['hoper', 'goat'], ['guttenberg', 'team'], ['ducks', 'younger'], ['teacher', 'rival'], ['there', 'money'], ['rockbart', 'forbidden'], ['vargas', 'chilenian'], ['bob', 'jean'], ['princess', 'cartoon'], ['first', 'anim'], ['wig', 'parent'], ['dialog', 'sappi'], ['broad', 'overli'], ['limit', 'forgiving'], ['dictat', 'racketeer'], ['lau', 'cheng'], ['melodi', 'half'], ['depression', 'detached'], ['worst', 'blindingli'], ['android', 'film'], ['suprem', 'bad'], ['space', 'not_feel'], ['galaxina', 'critic'], ['bunnyfluff', 'snigger'], ['choral', 'which'], ['stratton', 'pictur'], ['acting', 'davidson'], ['trek', 'understand'], ['odyssey', 'evok'], ['screentim', 'stratten'], ['verghese', 'patients'], ['mumbl', 'improvement'], ['value', 'two'], ['cavemen', 'frog'], ['book', 'miyazaki'], ['unintellig', 'total'], ['accompanist', 'unconsciousness'], ['pretty', 'trees'], ['adapt', 'fear'], ['brother', 'art'], ['blue', 'eye'], ['movi', 'bad'], ['demon', 'fx'], ['demon', 'gore'], ['pms', 'not_many'], ['zombi', 'cars'], ['crap', 'wanna'], ['demon', 'report'], ['demon', 'bava'], ['uneasili', 'subplots'], ['hustler', 'dialog'], ['commentary', 'social'], ['tv', 'awards'], ['film', 'charact'], ['feedback', 'maudlin'], ['novel', 'maddening'], ['art', 'sort'], ['show', 'lagass'], ['sex', 'brother'], ['boredom', 'schneider'], ['philosophizing', 'embroil'], ['curio', 'audibl'], ['glide', 'blue'], ['anti', 'confus'], ['ambul', 'fake'], ['show', 'cheater'], ['cheaters', 'episod'], ['men', 'male'], ['violent', 'bother'], ['lowbrow', 'highbrow'], ['tortur', 'chainsaw'], ['snuff', 'shock'], ['hustler', 'underground'], ['subplot', 'll'], ['minut', 'agent'], ['sick', 'director'], ['shock', 'ridicul'], ['killers', 'surveillance'], ['craft', 'appli'], ['not_famili', 'lynches'], ['agent', 'whole'], ['surveil', 'movi'], ['structured', 'hdnet'], ['cook', 'host'], ['becom', 'part'], ['buy', 'stickers'], ['hospit', 'mt'], ['hospit', 'alison'], ['blah', 'sully'], ['edgi', 'cancel'], ['hot', 'gone'], ['show', 'continu'], ['show', 'tonight'], ['terribl', 'baboon'], ['gun', 'hit'], ['rachel', 'shut'], ['awful', 'bullock'], ['friend', 'comment'], ['scavang', 'spotti'], ['cam', 'rack'], ['cover', 'name'], ['limburg', 'not_learn'], ['fishi', 'what'], ['dvd', 'complied'], ['66p', '66'], ['guy', 'metal'], ['rachael', 'show'], ['awful', 'sound'], ['whaddaya', 'dad'], ['nois', 'background'], ['bio', 'bonu'], ['movi', 'movie'], ['gunshot', 'hallway'], ['but', 'not_even'], ['soo', 'really'], ['guns', 'occup'], ['action', 'one'], ['area', 'demand'], ['horrible', 'ha'], ['butterfli', 'exceptions'], ['dog', 'interesting'], ['screentime', 'involvement'], ['on', 'headlin'], ['movie', 'small'], ['rate', 'user'], ['hafta', 'libraries'], ['red', 'guts'], ['porno', 'littl'], ['kahn', 'behavior'], ['twain', 'year'], ['flimsi', 'incit'], ['zombie', 'zombi'], ['zombi', 'zombies'], ['reports', 'idea'], ['zombi', 'flail'], ['muslim', 'outbreak'], ['commerci', 'redeem'], ['meant', 'not_meant'], ['not', 'not_comparing'], ['ugli', 'whales'], ['humour', 'remak'], ['stupid', 'kim'], ['dvd', 'ebay'], ['paus', 'found'], ['version', 'accent'], ['physic', 'molly'], ['cylon', 'ship'], ['babi', 'show'], ['biker', 'jocelyn'], ['joke', 'poor'], ['kahn', 'nathaniel'], ['pot', 'independ'], ['dumb', 'fun'], ['marijuana', 'weed'], ['road', 'indifferent'], ['see', 'blacks'], ['weed', 'movi'], ['nobodi', 'rock'], ['puppet', 'lord'], ['puppet', 'blade'], ['puppet', 'totems'], ['boys', 'hermit'], ['totem', 'puppets'], ['puppet', 'psychic'], ['not_convincing', 'leatherface'], ['gay', '70s'], ['sex', '70'], ['minut', 'littl'], ['serial', 'furnitur'], ['posted', 'thrilled'], ['supposedli', 'interview'], ['non', 'past'], ['averag', 'interlac'], ['priest', 'exorc'], ['possess', 'demon'], ['exorc', 'seem'], ['across', 'aw'], ['valley', 'dialog'], ['wateri', 'stool'], ['possess', 'priest'], ['purgatori', 'tu'], ['possess', 'whether'], ['dad', 'terribl'], ['dissapointment', 'amateur'], ['priest', 'pederast'], ['possess', 'sleep'], ['dialog', 'exorc'], ['isobel', 'priest'], ['exorc', 'exorcism'], ['isabelle', 'priest'], ['fandom', 'fan'], ['puppet', 'ruin'], ['polit', 'sacrilege'], ['leftist', 'hell'], ['medal', 'executed'], ['cursor', 'whole'], ['dante', 'poke'], ['kubrick', 'may'], ['video', 'obsessives'], ['film', 'kubrick'], ['lloyd', 'adams'], ['number', 'tale'], ['catch', 'continu'], ['post', 'win'], ['sequel', 'movies'], ['avail', 'mundan'], ['bed', 'frame'], ['loud', 'music'], ['centr', 'decid'], ['hillbilli', 'abo'], ['famili', '15'], ['affleck', 'atrophied'], ['duff', 'page'], ['miser', 'feel'], ['buscemi', 'affleck'], ['not_believable', 'depress'], ['cultures', 'appreci'], ['bed', 'eat'], ['rambling', 'backstori'], ['poe', 'tobi'], ['poe', 'fellini'], ['belushi', 'cult'], ['noticed', 'manager'], ['wired', 'features'], ['narrat', 'chickli'], ['belushi', 'deathb'], ['belushi', 'misjudg'], ['woodward', 'book'], ['rent', 'bed'], ['drug', 'autopsi'], ['dialogu', 'trower'], ['screener', 'claims'], ['song', 'soundtrack'], ['stoner', 'somehow'], ['inkl', 'kindergarten'], ['scant', 'apprar'], ['nobodi', 'book'], ['before', 'not_equ'], ['morgan', 'hopper'], ['deathbed', 'sex'], ['script', 'beards'], ['mad', 'morgan'], ['shark', 'reveng'], ['shark', 'ha'], ['shark', 'disappoints'], ['corni', 'bad'], ['honeymoon', 'underwat'], ['shark', 'sub'], ['bullsh', 'film'], ['shark', 'submarin'], ['kinki', 'sex'], ['bad', 'meet'], ['car', 'touch'], ['fi', 'sci'], ['respect', 'debacl'], ['from', 'star'], ['togeth', 'pimpl'], ['arm', 'hdtv'], ['inane', 'wincing'], ['creat', 'chimpanze'], ['low', 'kid'], ['episod', 'review'], ['eater', 'landown'], ['nativ', 'respect'], ['evan', 'skelet'], ['surveyor', 'cool'], ['mean', 'co'], ['reli', 'chop'], ['cgi', 'use'], ['bone', 'eater'], ['better', 'earli'], ['watch', 'waster'], ['serl', 'zones'], ['eater', 'bone'], ['check', 'sheriff'], ['eater', 'bone'], ['hot', 'develop'], ['boy', 'connect'], ['book', 'leper'], ['version', '1972'], ['ie', 'book'], ['book', 'tree'], ['locke', 'quit'], ['episod', 'we'], ['featurett', 'monster'], ['prescott', 'dan'], ['monkey', 'fright'], ['mutat', 'creatur'], ['woods', 'sadly'], ['monster', 'however'], ['woods', 'wood'], ['gorilla', 'never'], ['dread', 'terribly'], ['monster', 'very'], ['abit', 'unfinish'], ['screen', 'monster'], ['spend', 'helmet'], ['boring', 'noth'], ['giant', 'on'], ['agar', 'hair'], ['slow', 'kung'], ['vampir', 'rathbone'], ['suprem', 'movi'], ['box', 'film'], ['vampir', 'awful'], ['fawn', 'teas'], ['horrible', 'riddl'], ['eject', 'criticism'], ['weapons', 'lit'], ['xx', 'do'], ['purpl', 'cape'], ['nauseating', 'don'], ['store', 'took'], ['poor', 'quilting'], ['crap', 'cut'], ['abl', 'chang'], ['fight', 'switches'], ['realli', 'narr'], ['laugh', 'vampir'], ['low', 'budget'], ['suck', 'assassin'], ['basement', 'vampir'], ['african', 'blade'], ['vampir', 'assassins'], ['location', 'fact'], ['mean', 'caus'], ['hooker', 'fellow'], ['gangster', 'dress'], ['cannonbal', 'slid'], ['game', 'kit'], ['soccer', 'extra'], ['veri', 'overacted'], ['adopt', 'dog'], ['dog', 'horrible'], ['jumbo', 'ludicrous'], ['interest', 'student'], ['hemingway', 'back'], ['toole', 'poor'], ['eighti', 'spano'], ['crichton', 'asid'], ['seagal', 'either'], ['prison', 'guard'], ['action', 'sayonara'], ['butt', 'kick'], ['he', 'fight'], ['ja', 'irrit'], ['hero', 'keep'], ['requir', 'contain'], ['seagal', 'action'], ['inmat', 'bunch'], ['tommi', 'pta'], ['not', 'kick'], ['prison', 'he'], ['machinegun', 'fight'], ['stereotypes', 'gratuit'], ['aveng', 'kaufman'], ['toxi', 'dark'], ['original', 'brainer'], ['bearli', 'differ'], ['sumo', 'movi'], ['toxi', 'gori'], ['nothing', 'crap'], ['not_watch', 'disast'], ['convo', 'mite'], ['famou', 'humor'], ['gay', 'not_veri'], ['kiss', 'annoy'], ['gratuit', 'week'], ['gay', 'say'], ['screenplay', 'hollywood'], ['movi', 'not'], ['poker', 'game'], ['kong', 'donkey'], ['game', 'poker'], ['darci', 'collins'], ['adapt', 'singl'], ['factor', 'vapor'], ['alien', 'copi'], ['deputi', 'nightbeast'], ['1951', 'monster'], ['terribl', 'style'], ['remote', 'dairi'], ['somebodi', 'not'], ['game', 'graphic'], ['director', 'avoid'], ['spider', 'superhero'], ['content', 'cuss'], ['light', 'coupl'], ['scari', 'send'], ['friend', 'movi'], ['crude', 'not_believ'], ['superhero', 'thought'], ['drake', 'movie'], ['meet', 'superhero'], ['tank', 'holiday'], ['13', 'movie'], ['for', 'trollop'], ['barrel', 'movi'], ['spoof', '1st'], ['glad', 'disappoint'], ['spoof', 'recent'], ['fugitive', 'ass'], ['99', 'dare'], ['idaho', 'karaok'], ['seriou', 'attempt'], ['flight', 'lame'], ['click', 'ribisi'], ['mayb', 'place'], ['empti', 'offer'], ['mod', 'squad'], ['basic', 'movi'], ['televis', 'ignorant'], ['barnes', 'cochran'], ['jackal', 'boot'], ['cool', 'noooooooo'], ['snack', 'awake'], ['magic', 'pilot'], ['look', 'old'], ['whenever', 'quarters'], ['squad', 'danes'], ['beyond', 'not_scream'], ['cool', 'hip'], ['flaw', 'wardrobes'], ['number', 'walk'], ['seri', 'dane'], ['not_onc', 'colors'], ['petit', 'advis'], ['so', 'discussions'], ['yr', 'drove'], ['mod', 'squad'], ['offic', 'sort'], ['mod', 'squad'], ['auteur', 'note'], ['camp', 'clich'], ['camp', 'nudity'], ['whatsoever', 'terribl'], ['disappoint', 'promis'], ['friend', 'drug'], ['rock', 'detroit'], ['actual', 'dialogu'], ['rock', 'roll'], ['stuff', 'oevre'], ['movi', 'departed'], ['invisible', 'monoton'], ['kid', 'station'], ['pull', 'off'], ['bugged', 'stirring'], ['island', 'violenc'], ['cut', 'someth'], ['jazz', 'club'], ['hauer', 'pregnant'], ['sing', 'element'], ['felt', 'dribble'], ['enchanted', 'background'], ['ami', 'slew'], ['montalban', 'goon'], ['border', 'dull'], ['arthur', 'suddenli'], ['oh', 'hellrais'], ['dog', 'without'], ['drop', 'smithe'], ['hell', 'credit'], ['hell', 'cenobit'], ['antholog', 'defending'], ['demons', 'evil'], ['moon', 'full'], ['blah', 'pinhead'], ['umpteenth', 'naff'], ['hellraiser', 'influenc'], ['franchis', 'box'], ['wretch', 'inferno'], ['merchant', 'rant'], ['37', 'filmmak'], ['bloodlin', 'still'], ['dancer', 'ballet'], ['birth', 'oper'], ['deform', 'pave'], ['arrog', 'cheap'], ['point', 'dialogu'], ['conflict', 'story'], ['lame', 'accurate'], ['conclus', 'cinemaphotographi'], ['th', 'sean'], ['film', 'jock'], ['movi', 'crore'], ['god', 'film'], ['english', 'amaz'], ['english', 'dub'], ['poor', 'song'], ['no', 'movi'], ['shown', 'watch'], ['himesh', 'crow'], ['reshammiya', 'scenes'], ['himesh', 'wrong'], ['37', 'youth'], ['not_put', 'actu'], ['hr', 'hold'], ['000', 'himesh'], ['letter', 'censored'], ['rubber', 'laugh'], ['scriptwritt', 'filming'], ['car', 'bad'], ['lame', 'fang'], ['hiss', 'engel'], ['vampir', 'film'], ['afterward', 'not'], ['mere', 'howev'], ['not_entertaining', 'vampires'], ['smile', 'movi'], ['vampir', 'quit'], ['caven', 'howarth'], ['snake', 'men'], ['fight', 'overs'], ['snake', 'geek'], ['shoot', 'baad'], ['closeup', 'tha'], ['movi', 'applaud'], ['improv', 'realli'], ['troy', 'execut'], ['mastermind', 'doesn'], ['shatter', 'scepter'], ['choos', 'bad'], ['sidekick', 'lines'], ['concur', 'money'], ['hell', 'neame'], ['bad', 'cop'], ['54', 'centuries'], ['teenager', 'deal'], ['dr', 'weenick'], ['annoy', 'plu'], ['not_som', 'stunk'], ['not_finish', 'exemplifi'], ['operas', 'discrimination'], ['dumbfound', 'crossroads'], ['men', 'premise'], ['men', 'man'], ['genet', 'male'], ['epic', 'third'], ['fi', 'sci'], ['elephant', '37'], ['mistak', 'past'], ['convinc', 'questionnair'], ['viru', 'men'], ['un', 'happening'], ['subject', 'matter'], ['conflict', 'harper'], ['stock', 'ceo'], ['alecbaldwin', 'not_strong'], ['tire', 'better'], ['carrey', 'fletcher'], ['im', 'understand']]\n",
      "#Docs vector Pos:(800, 17593) #Docs vector Neg:(800, 17593) \n"
     ]
    }
   ],
   "source": [
    "Pos_labels = labelVector(Ptr1,tfidf,2)\n",
    "Neg_labels = labelVector(Ntr1,tfidf,2)\n",
    "print(f\"#Positive labels:{Pos_labels}\")\n",
    "print(f\"#Negative labels:{Neg_labels}\")\n",
    "print(f\"#Docs vector Pos:{Ptr1.shape} #Docs vector Neg:{Ntr1.shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Dimensionality Reduction:\n",
    "1. **Application of PCA**:\n",
    "   - PCA (Principal Component Analysis) is applied to the features (`X`) to reduce the dimensionality of the data while preserving the most important information.\n",
    "   - The number of components is specified as `n_components=200`, indicating that PCA should retain 200 principal components.\n",
    "2. **Why 200?**\n",
    "   - after considering most of the options for the `n_components' , 200 was the best option form most of the classifiers since it gave the best accuracies for most of them. This number were the best considering 800 docs for each type and considering the same perpross steps\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PCA_0     PCA_1     PCA_2     PCA_3     PCA_4     PCA_5     PCA_6  \\\n",
      "0     0.054057 -0.073073  0.100591 -0.013354 -0.028381 -0.055616 -0.018246   \n",
      "1    -0.106017  0.027426  0.020031 -0.010995  0.052823  0.029953 -0.048126   \n",
      "2    -0.090625 -0.054957  0.074834  0.014625  0.029072 -0.017850  0.001629   \n",
      "3     0.084769  0.083155  0.081624  0.021091  0.034986 -0.034290  0.040298   \n",
      "4    -0.082186  0.001183  0.102717  0.041543  0.032456 -0.034253 -0.000146   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1595  0.066213 -0.017877 -0.072605 -0.010025  0.015686  0.013605  0.031906   \n",
      "1596 -0.004913 -0.011009  0.019648  0.018793 -0.052124 -0.032732 -0.022572   \n",
      "1597  0.094854 -0.047298  0.039689  0.023226  0.015536 -0.046977  0.005818   \n",
      "1598 -0.012139  0.009943 -0.005844 -0.005769  0.064222  0.001411  0.065654   \n",
      "1599  0.109990 -0.001594 -0.007182 -0.054473 -0.052976 -0.008976  0.030643   \n",
      "\n",
      "         PCA_7     PCA_8     PCA_9  ...   PCA_191   PCA_192   PCA_193  \\\n",
      "0     0.004481  0.021843  0.041767  ... -0.013400  0.009941  0.032957   \n",
      "1     0.061796  0.034830  0.041429  ... -0.048974 -0.007424  0.072140   \n",
      "2    -0.036196  0.023734  0.014621  ... -0.071116  0.061993  0.004946   \n",
      "3     0.026129  0.002320 -0.058210  ... -0.018723 -0.034803  0.011571   \n",
      "4    -0.002551 -0.005033  0.000679  ... -0.008826  0.069589 -0.014744   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1595 -0.021530  0.007020 -0.019727  ...  0.082787  0.034391  0.018606   \n",
      "1596  0.022215 -0.014099  0.030014  ... -0.001644  0.012295 -0.012500   \n",
      "1597  0.029922  0.022440  0.028742  ... -0.035783  0.020998  0.010582   \n",
      "1598  0.034688  0.016134  0.008010  ... -0.006104 -0.024574  0.004067   \n",
      "1599 -0.106904  0.003881 -0.057386  ... -0.006039 -0.035392  0.000678   \n",
      "\n",
      "       PCA_194   PCA_195   PCA_196   PCA_197   PCA_198   PCA_199  Label  \n",
      "0     0.022060 -0.016056  0.021826  0.002114  0.003046  0.046080      1  \n",
      "1     0.005107  0.022776 -0.008799 -0.009610  0.047735 -0.019446      1  \n",
      "2     0.009757  0.018674 -0.000679 -0.059665  0.040462  0.030350      1  \n",
      "3     0.055769  0.028108  0.030560  0.029758 -0.009498  0.035838      1  \n",
      "4     0.011373  0.030088  0.030123 -0.043694 -0.039829 -0.005463      1  \n",
      "...        ...       ...       ...       ...       ...       ...    ...  \n",
      "1595 -0.044670  0.022516  0.007765 -0.004566  0.039833  0.037834      0  \n",
      "1596  0.017619 -0.017865 -0.016410 -0.008695  0.030021  0.022123      0  \n",
      "1597 -0.016381  0.038596 -0.020419 -0.040657 -0.007343  0.074702      0  \n",
      "1598 -0.033177  0.012067 -0.060491 -0.031198  0.013300  0.097075      0  \n",
      "1599 -0.009808  0.007823 -0.007150  0.016928 -0.043656 -0.024748      0  \n",
      "\n",
      "[1600 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming Ptr1 and Ntr1 are your feature matrices for positive and negative samples respectively\n",
    "\n",
    "# Create dataframes for positive and negative samples with labels\n",
    "TrainVecPos = pd.DataFrame(Ptr1)\n",
    "TrainVecPos[\"Label\"] = 1\n",
    "\n",
    "TrainVecNeg = pd.DataFrame(Ntr1)\n",
    "TrainVecNeg[\"Label\"] = 0\n",
    "\n",
    "# Concatenate the positive and negative dataframes\n",
    "TrainVecSet3_pca = pd.concat([TrainVecPos, TrainVecNeg], axis=0)\n",
    "\n",
    "# Separate features (X) and labels (Y)\n",
    "Y = TrainVecSet3_pca['Label']\n",
    "X = TrainVecSet3_pca.drop(['Label'], axis=1)\n",
    "\n",
    "# Apply PCA to the features\n",
    "pca = PCA(n_components=200)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Create a new dataframe with reduced features and labels\n",
    "TrainVecSet3 = pd.DataFrame(X_pca, columns=[f\"PCA_{i}\" for i in range(X_pca.shape[1])])\n",
    "TrainVecSet3['Label'] = Y.reset_index(drop=True)  # Reset index of labels\n",
    "print(TrainVecSet3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:(1200, 200) Labels Train: (1200, 1)\tTest:(400, 200) Labels Test: (400, 1) \n"
     ]
    }
   ],
   "source": [
    "# extracting training and test set \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# task: scale the data\n",
    "\n",
    "# Y is label: {1,0}\n",
    "Y = TrainVecSet3[['Label']]\n",
    "\n",
    "# X is everything without label\n",
    "X = TrainVecSet3.drop(['Label'], 1)\n",
    "\n",
    "# extract train and test set\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = .25)\n",
    "\n",
    "print(f\"Train:{trainX.shape} Labels Train: {trainY.shape}\\tTest:{testX.shape} Labels Test: {testY.shape} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:(1200, 200) Labels Train: (1200, 1)\tTest:(400, 200) Labels Test: (400, 1) \n"
     ]
    }
   ],
   "source": [
    "## scale \n",
    "scaler = StandardScaler()  \n",
    "\n",
    "# Fit only on training data\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scale = scaler.transform(X)  \n",
    "\n",
    "# extract train and test set\n",
    "trainX, testX, trainY, testY = train_test_split(X_scale, Y, test_size = .25)\n",
    "\n",
    "print(f\"Train:{trainX.shape} Labels Train: {trainY.shape}\\tTest:{testX.shape} Labels Test: {testY.shape} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Classifiers\n",
    "\n",
    "1. **Data Preprocessing**:\n",
    "   - After preprocessing the data as described earlier, including tokenization, removing stopwords, stemming, and potentially applying dimensionality reduction techniques like PCA, the data is now ready for training.\n",
    "   \n",
    "2. **Classifier Training**:\n",
    "     - Support Vector Machines (SVM)\n",
    "     - Random Forest\n",
    "     - Naive Bayes\n",
    "     - MLP\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.70      0.91      0.79       193\n",
      "         Pos       0.88      0.64      0.74       207\n",
      "\n",
      "    accuracy                           0.77       400\n",
      "   macro avg       0.79      0.77      0.77       400\n",
      "weighted avg       0.79      0.77      0.77       400\n",
      "\n",
      "Confusion Matrix:\n",
      " [[175  18]\n",
      " [ 74 133]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "NBmodel = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "NBmodel.fit(trainX, trainY[\"Label\"])\n",
    "\n",
    "#Predict Output\n",
    "Y_Bayes = NBmodel.predict(testX)\n",
    "\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], Y_Bayes, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=testY[\"Label\"], y_pred=Y_Bayes))\n",
    "\n",
    "fig = plot_confusion_matrix(NBmodel, testX, testY, display_labels=NBmodel.classes_)\n",
    "fig.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross-Validation (will be applied for all classifiers)\n",
    "\n",
    "1. **Small Sample Size Consideration**:\n",
    "   - Due to the relatively small sample size of the dataset, traditional train-test splitting may result in high variance in model performance metrics. Cross-validation techniques are employed to mitigate this issue and obtain more reliable estimates of model performance.\n",
    "\n",
    "2. **Choice of Cross-Validation Technique**:\n",
    "   - Leave-One-Out (LOO) cross-validation, where each sample is used as a separate test set, theoretically provides the most accurate estimation of model performance. However, it can be computationally expensive, especially for larger datasets. In this case, with a relatively small dataset, 10-fold cross-validation is chosen as a compromise between accuracy and computational efficiency.\n",
    "\n",
    ".\n",
    "\n",
    "3. **Benefits of 10-Fold Cross-Validation**:\n",
    "   - 10-fold cross-validation provides a robust estimation of model performance while being computationally more efficient than LOO cross-validation.\n",
    "   - It helps in assessing the generalization capability of the model and identifying potential overfitting or underfitting issues.\n",
    "   \n",
    "\n",
    "4. **Empirical Validation of 10-Fold Cross-Validation**:\n",
    "   - Through empirical testing, it has been found that 10-fold cross-validation yields accurate estimates of model performance while being significantly faster than LOO cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "{'fit_time': 0.011481356620788575, 'score_time': 0.010443854331970214, 'test_accuracy': 0.73375, 'test_precision_neg': 0.6914002736469745, 'test_precision_pos': 0.8043613943311367, 'test_recall_neg': 0.85, 'test_recall_pos': 0.6175, 'test_f1_score': 0.697203193679732}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define custom scoring functions for precision and recall for positive and negative classes\n",
    "def precision_neg(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, pos_label=0)  # Negative class label is 0\n",
    "\n",
    "def precision_pos(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, pos_label=1)  # Positive class label is 1\n",
    "\n",
    "def recall_neg(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)  # Negative class label is 0\n",
    "\n",
    "def recall_pos(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=1)  # Positive class label is 1\n",
    "\n",
    "# Extract labels (Y) and features (X)\n",
    "Y = TrainVecSet3[['Label']]\n",
    "X = TrainVecSet3.drop(['Label'], 1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Create a Gaussian Classifier\n",
    "NBmodel = GaussianNB()\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_results = cross_validate(NBmodel, X_scaled, Y[\"Label\"], cv=cv, scoring=scoring)\n",
    "\n",
    "results_NB = {}\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-validation results:\")\n",
    "for metric, values in cross_val_results.items():\n",
    "    results_NB[metric] = values.mean()\n",
    "print(results_NB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.78      0.89      0.83       193\n",
      "         Pos       0.88      0.77      0.82       207\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.83      0.83      0.82       400\n",
      "weighted avg       0.83      0.82      0.82       400\n",
      "\n",
      "Confusion Matrix:\n",
      " [[171  22]\n",
      " [ 48 159]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.096882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.023212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.019073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.002460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.002416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.002180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     importance\n",
       "2      0.096882\n",
       "0      0.060857\n",
       "10     0.023212\n",
       "3      0.019613\n",
       "9      0.019073\n",
       "..          ...\n",
       "75     0.002460\n",
       "97     0.002430\n",
       "109    0.002416\n",
       "107    0.002369\n",
       "66     0.002180\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(trainX, trainY[\"Label\"]);\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "Y_rf = rf.predict(testX)\n",
    "\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], Y_rf, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=testY[\"Label\"], y_pred=Y_rf))\n",
    "\n",
    "# print feature Importances\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "{'fit_time': 1.4755953550338745, 'score_time': 0.031944680213928225, 'test_accuracy': 0.83375, 'test_precision_neg': 0.8167987265223691, 'test_precision_pos': 0.8543962778539411, 'test_recall_neg': 0.8625, 'test_recall_pos': 0.805, 'test_f1_score': 0.8283971277316317}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Gaussian Classifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_results = cross_validate(rf, X_scaled, Y[\"Label\"], cv=cv, scoring=scoring)\n",
    "\n",
    "results_RF = {}\n",
    "print(\"Cross-validation results:\")\n",
    "for metric, values in cross_val_results.items():\n",
    "    results_RF[metric] = values.mean()\n",
    "print(results_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.84      0.82      0.83       193\n",
      "         Pos       0.84      0.85      0.84       207\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.84      0.84      0.84       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  34]\n",
      " [ 31 176]]\n"
     ]
    }
   ],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(trainX, trainY[\"Label\"])\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Y_clf = clf.predict(testX)\n",
    "\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], Y_clf, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=testY[\"Label\"], y_pred=Y_clf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': 1.510220217704773, 'score_time': 0.015273094177246094, 'test_accuracy': 0.8631249999999999, 'test_precision_neg': 0.8641430963424138, 'test_precision_pos': 0.8632857859678122, 'test_recall_neg': 0.8625, 'test_recall_pos': 0.8637500000000001, 'test_f1_score': 0.8631811437403378}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Gaussian Classifier\n",
    "clf2 = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_results = cross_validate(clf2, X_scaled, Y[\"Label\"], cv=cv, scoring=scoring)\n",
    "\n",
    "# Print the cross-validation results\n",
    "results_SVM = {}\n",
    "for metric, values in cross_val_results.items():\n",
    "    results_SVM[metric] = values.mean()\n",
    "print(results_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.83      0.83      0.83       193\n",
      "         Pos       0.84      0.84      0.84       207\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.83      0.83      0.83       400\n",
      "weighted avg       0.84      0.83      0.84       400\n",
      "\n",
      "Confusion Matrix:\n",
      " [[161  32]\n",
      " [ 34 173]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# instatiate classifier\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100,100), random_state=1)\n",
    "\n",
    "mlp.fit(trainX, trainY[\"Label\"])\n",
    "\n",
    "pred_Y = mlp.predict(testX)\n",
    "\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], pred_Y, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=testY[\"Label\"], y_pred=pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': 0.992253303527832, 'score_time': 0.01322622299194336, 'test_accuracy': 0.86, 'test_precision_neg': 0.8581813194056013, 'test_precision_pos': 0.8645008818342153, 'test_recall_neg': 0.865, 'test_recall_pos': 0.8549999999999999, 'test_f1_score': 0.8588989114938339}\n"
     ]
    }
   ],
   "source": [
    "mlp2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100,100), random_state=1)\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_results = cross_validate(mlp2, X_scaled, Y[\"Label\"], cv=cv, scoring=scoring)\n",
    "\n",
    "# Print the cross-validation results\n",
    "results_MLP = {}\n",
    "for metric, values in cross_val_results.items():\n",
    "    results_MLP[metric] = values.mean()\n",
    "print(results_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Precision and Recall for Various Classifiers\n",
    "This script uses matplotlib.pyplot to create bar plots that compare the precision and recall scores for different classifiers. The plots illustrate the performance of four classifiers—Naive Bayes, Random Forest, Support Vector Machine (SVM), and Multi-Layer Perceptron (MLP)—in terms of precision and recall for both positive and negative classes.\n",
    "\n",
    "## Grouped Bar Plot for Precision\n",
    "To visualize precision, a grouped bar plot is created:\n",
    "- **bar_width**: Width of each bar in the plot.\n",
    "- **r1**: X positions for the first set of bars (corresponding to positive class precision).\n",
    "- **r2**: X positions for the second set of bars (corresponding to negative class precision). \n",
    "\n",
    "## Similarily a Grouped Bar Plot is created for recall\n",
    "\n",
    "## Results:\n",
    "Generally, we noticed that SVM and MLP classifiers results are close to each other and they had the highest precision and recall compared to all the classifiers used (except the stacking classifier which had the highest accuracy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classifiers = ['Naive Bayes', 'Random Forest', 'SVM', 'MLP']\n",
    "precision_pos_scores = [results_NB['test_precision_pos'], results_RF['test_precision_pos'], results_SVM['test_precision_pos'], results_MLP['test_precision_pos']]\n",
    "precision_neg_scores = [results_NB['test_precision_neg'], results_RF['test_precision_neg'], results_SVM['test_precision_neg'], results_MLP['test_precision_neg']]\n",
    "\n",
    "recall_pos_scores = [results_NB['test_recall_pos'], results_RF['test_recall_pos'], results_SVM['test_recall_pos'], results_MLP['test_recall_pos']]\n",
    "recall_neg_scores = [results_NB['test_recall_neg'], results_RF['test_recall_neg'], results_SVM['test_recall_neg'], results_MLP['test_recall_neg']]\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the x locations for the groups\n",
    "r1 = range(len(classifiers))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Plot the grouped bar plot for precision\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(r1, precision_pos_scores, color='blue', width=bar_width, edgecolor='grey', label='Precision (Positive class)')\n",
    "plt.bar(r2, precision_neg_scores, color='red', width=bar_width, edgecolor='grey', label='Precision (Negative class)')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Classifier', fontweight='bold')\n",
    "plt.xticks([r + bar_width/2 for r in range(len(classifiers))], classifiers)\n",
    "\n",
    "# Add y label\n",
    "plt.ylabel('Precision', fontweight='bold')\n",
    "\n",
    "# Add title\n",
    "plt.title('Precision for Positive and Negative Classes by Classifier')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Plot the grouped bar plot for recall\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(r1, recall_pos_scores, color='blue', width=bar_width, edgecolor='grey', label='Recall (Positive class)')\n",
    "plt.bar(r2, recall_neg_scores, color='red', width=bar_width, edgecolor='grey', label='Recall (Negative class)')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Classifier', fontweight='bold')\n",
    "plt.xticks([r + bar_width/2 for r in range(len(classifiers))], classifiers)\n",
    "\n",
    "# Add y label\n",
    "plt.ylabel('Recall', fontweight='bold')\n",
    "\n",
    "# Add title\n",
    "plt.title('Recall for Positive and Negative Classes by Classifier')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Added the stacking method to improve accuracy\n",
    "\n",
    "## About the method:\n",
    "One way to improve accuracy is to implement stacking. This method generally combines the results of multiple classifiers to improve accuracy. The key advantage of stacking is that it leverages the strengths of multiple models, potentially reducing individual weaknesses and increasing accuracy.\n",
    "\n",
    "## Steps:\n",
    "1. **Base Models**: In stacking, you start by training multiple base models on the same dataset. In our case we chose: Naive Bayes, Random Forest, and SVM to be our base models.\n",
    "2. **Meta-Model**: After training the base models, their predictions are used to create a new dataset. This dataset is then used to train a meta-model. The inputs to the meta-model are the predictions from the base models, and the outputs are the actual target values. In our case, the meta model was MLP.\n",
    "3. **Final Prediction**: Once the meta-model is trained, it can be used to make predictions on new data. Typically, the base models make predictions, and then the meta-model combines these predictions to produce a final output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.83      0.92      0.87       193\n",
      "         Pos       0.91      0.83      0.87       207\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.87      0.87      0.87       400\n",
      "weighted avg       0.87      0.87      0.87       400\n",
      "\n",
      "Confusion Matrix:\n",
      " [[177  16]\n",
      " [ 36 171]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define base classifiers\n",
    "base_classifiers = [\n",
    "    ('naive_bayes', GaussianNB()),  # Naïve Bayes\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42)),  # Random Forest\n",
    "    ('svm', svm.SVC(kernel='linear'))  # SVM\n",
    "]\n",
    "\n",
    "# Define meta-classifier\n",
    "meta_classifier = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1)\n",
    "\n",
    "# Create stacking classifier with base classifiers and MLP as meta\n",
    "stacking_classifier = StackingClassifier(estimators=base_classifiers, final_estimator=meta_classifier, cv=10)\n",
    "\n",
    "# Train the stacking classifier on the training data\n",
    "stacking_classifier.fit(trainX, trainY[\"Label\"])\n",
    "\n",
    "# Make predictions on the test data\n",
    "pred_Y = stacking_classifier.predict(testX)\n",
    "\n",
    "# Output classification report and confusion matrix\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], pred_Y, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(testY[\"Label\"], pred_Y))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
